{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from tqdm  import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as ch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robustness import model_utils, datasets, train, defaults\n",
    "from robustness.datasets import ImageNet\n",
    "from robustness.tools import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor\n",
    "from pytorch_quantization import quant_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ch.device(\"cuda\" if (ch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dataset and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 4\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard-coded dataset, architecture, batch size, workers\n",
    "ds = ImageNet('../../datasets/ImageNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = ds.make_loaders(batch_size=BATCH_SIZE, workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the quantized model and calibrate it with the training dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create quantized model\n",
    "quant_modules.initialize() # have to deactivate after using\n",
    "quant_desc_input = QuantDescriptor(calib_method='histogram')\n",
    "quant_nn.QuantConv2d.set_default_quant_desc_input(quant_desc_input)\n",
    "quant_nn.QuantLinear.set_default_quant_desc_input(quant_desc_input)\n",
    "\n",
    "m, checkpoint = model_utils.make_and_restore_model(parallel= True, arch='resnet50', dataset=ds, resume_path= '../../weights/imagenet_linf_8.pt')\n",
    "q_model = models.resnet50(pretrained=True)\n",
    "q_model.load_state_dict(m.model.state_dict())\n",
    "q_model = q_model.to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Calibrate the model with train dataset\n",
    "def collect_stats(model, data_loader, num_batches):\n",
    "    \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "     # Enable calibrators\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.disable_quant()\n",
    "                module.enable_calib()\n",
    "            else:\n",
    "                module.disable()\n",
    "\n",
    "    for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "        model(image.cuda())\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "\n",
    "     # Disable calibrators\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.enable_quant()\n",
    "                module.disable_calib()\n",
    "            else:\n",
    "                module.enable()\n",
    "\n",
    "def compute_amax(model, **kwargs):\n",
    "     # Load calib result\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                    module.load_calib_amax()\n",
    "                else:\n",
    "                    module.load_calib_amax(**kwargs)\n",
    "            print(F\"{name:40}: {module}\")\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# It is a bit slow since we collect histograms on CPU\n",
    "with ch.no_grad():\n",
    "    collect_stats(q_model, train_loader, num_batches=2)\n",
    "    compute_amax(q_model, method=\"percentile\", percentile=99.99)\n",
    "\n",
    "ch.save(q_model.state_dict(), '../../weights/q_imagenet_linf_8.pt')\n",
    "quant_modules.deactivate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model.load_state_dict(ch.load('../../weights/q_imagenet_linf_8.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_modules.deactivate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, checkpoint = model_utils.make_and_restore_model(parallel= True, arch='resnet50', dataset=ds, resume_path= '../../weights/imagenet_linf_8.pt')\n",
    "fp_model = models.resnet50(pretrained=True)\n",
    "fp_model.load_state_dict(m.model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model = q_model.to(device)\n",
    "fp_model = fp_model.to(device)\n",
    "fp_model.eval()\n",
    "q_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = helpers.InputNormalize(ch.tensor([0.485, 0.456, 0.406]).to(device), ch.tensor([0.229, 0.224, 0.225]).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Clean Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tqdm(enumerate(val_loader), total=len(val_loader))\n",
    "total = 0\n",
    "q_correct = 0\n",
    "fp_correct = 0\n",
    "for i, (inp, target) in iterator:\n",
    "    target = target.cuda(non_blocking=True)\n",
    "    inp = normalizer(inp.cuda())\n",
    "    \n",
    "    q_logits = q_model(inp)\n",
    "    _, q_pred = q_logits.topk(1, 1, True, True)\n",
    "    q_pred = q_pred.t()[0]\n",
    "    q_correct += (q_pred == target).sum().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    fp_logits = fp_model(inp)\n",
    "    _, fp_pred = fp_logits.topk(1, 1, True, True)\n",
    "    fp_pred = fp_pred.t()[0]\n",
    "    fp_correct += (fp_pred == target).sum().cpu().numpy()\n",
    "    \n",
    "    total += BATCH_SIZE\n",
    "    ch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('fp clean accuracy: ' + str(fp_correct/total) + '  clean accuracy: ' + str(q_correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "def fgsm_attack(image, orig_img, step, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    adv_image = image + step*sign_data_grad\n",
    "    \n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    A = ch.clamp(adv_image - orig_img, -epsilon, epsilon)\n",
    "    perturbed_image = ch.clamp(orig_img + A, 0, 1)\n",
    "\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ch.nn.CrossEntropyLoss()\n",
    "def PGD( model, fp_model, device, test_loader, step, epsilon, grad_iterations):\n",
    "    \n",
    "    model.eval()\n",
    "    fp_model.eval()\n",
    "    # Accuracy counter\n",
    "    success = 0\n",
    "    Agree = 0\n",
    "    q_wrong = 0\n",
    "    fp_correct = 0\n",
    "    Q_success = 0\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    iterator = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    for i, (data, target) in  iterator:\n",
    "        \n",
    "        # Send the data and label to the device\n",
    "        # data = ch.clamp(data + 2 * (ch.rand_like(data) - 0.5) * epsilon, 0, 1)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        q_pred = model(normalizer(data).cuda()).max(1, keepdim=True)[1].t()[0] # get the index of the max log-probability\n",
    "        fp_pred = fp_model(normalizer(data)).max(1, keepdim=True)[1].t()[0] # get the index of the max log-probability\n",
    "        \n",
    "        index = ch.logical_and((target == q_pred), (target == fp_pred))\n",
    "        Q_success += ch.sum(ch.logical_not(target == q_pred))\n",
    "        data = data[index]\n",
    "        target = target[index]\n",
    "        orig_cpy = data.clone().detach()\n",
    "        Agree += len(target)\n",
    "        \n",
    "        \n",
    "        for iters in range(0,grad_iterations):\n",
    "            \n",
    "            if len(target) == 0:\n",
    "                continue\n",
    "            \n",
    "            data = data.clone().detach().requires_grad_(True)\n",
    "            \n",
    "            output = model(normalizer(data))\n",
    "            loss = criterion(output,target)\n",
    "            \n",
    "            # Zero all existing gradients\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # Calculate gradients of model in backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Collect datagrad\n",
    "            data_grad = data.grad.data\n",
    "            \n",
    "            # Call FGSM Attack\n",
    "            perturbed_data = fgsm_attack(data, orig_cpy, step, epsilon, data_grad)\n",
    "\n",
    "            # Re-classify the perturbed image\n",
    "            q_pred = model(normalizer(perturbed_data)).max(1, keepdim=True)[1].t()[0]\n",
    "            fp_pred = fp_model(normalizer(perturbed_data)).max(1, keepdim=True)[1].t()[0]\n",
    "\n",
    "            # Check for success\n",
    "            q_w = ch.logical_not(target == q_pred)\n",
    "            fp_c = (target == fp_pred)\n",
    "            \n",
    "            fp_c_q_w = ch.logical_and(q_w, fp_c)\n",
    "            index = ch.logical_not(fp_c_q_w)\n",
    "            \n",
    "            data = perturbed_data[index]\n",
    "            orig_cpy = orig_cpy[index]\n",
    "            \n",
    "            success += ch.sum(fp_c_q_w)\n",
    "            q_wrong += ch.sum(fp_c_q_w)\n",
    "            Q_success += ch.sum(fp_c_q_w)\n",
    "            fp_correct += ch.sum(fp_c_q_w)\n",
    "            \n",
    "            target = target[index]\n",
    "            \n",
    "            if iters == (grad_iterations -1) or len(target) == 0:\n",
    "                q_wrong += ch.sum(ch.logical_and(q_w, index))\n",
    "                fp_correct += ch.sum(ch.logical_and(fp_c, index))\n",
    "                Q_success += ch.sum(ch.logical_and(q_w, index))\n",
    "\n",
    "        ch.cuda.empty_cache()\n",
    "        # Calculate final accuracy for this epsilon\n",
    "        if i%100 == 0:\n",
    "            print(\"Total: {} \\t Success: {} \\t Q_W:{} \\t FP_W:{} \\t Robust_acc: {:.2f} \".format(Agree, success, q_wrong ,Agree - fp_correct, 100* (1- Q_success/((i+1) *BATCH_SIZE)) ))\n",
    "    print(\"Total: {} \\t Success: {} \\t Q_W:{} \\t FP_W:{} \\t Robust_acc: {:.2f} \".format(Agree, success, q_wrong ,Agree - fp_correct, 100* (1- Q_success/((i+1) *BATCH_SIZE)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PGD(q_model, fp_model, device, val_loader, 0.00375, 0.03, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diva_criterion = ch.nn.Softmax()\n",
    "def DIVA(q_model, fp_model, c, device, test_loader, step, epsilon, grad_iterations):\n",
    "    \n",
    "    q_model.eval()\n",
    "    fp_model.eval()\n",
    "    # Accuracy counter\n",
    "    success = 0\n",
    "    Agree = 0\n",
    "    q_wrong = 0\n",
    "    fp_correct = 0\n",
    "    Q_success = 0\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    iterator = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    for i, (data, target) in  iterator:\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        q_pred = q_model(normalizer(data)).max(1, keepdim=True)[1].t()[0] # get the index of the max log-probability\n",
    "        fp_pred = fp_model(normalizer(data)).max(1, keepdim=True)[1].t()[0] # get the index of the max log-probability\n",
    "        \n",
    "        index = ch.logical_and((target == q_pred), (target == fp_pred))\n",
    "        Q_success += ch.sum(ch.logical_not(target == q_pred))\n",
    "        data = data[index]\n",
    "        target = target[index]\n",
    "        orig_cpy = data.clone().detach()\n",
    "        Agree += len(target)\n",
    "        \n",
    "        for iters in range(0,grad_iterations):\n",
    "            \n",
    "            if len(target) == 0:\n",
    "                continue\n",
    "            \n",
    "            data = data.clone().detach().requires_grad_(True)\n",
    "            \n",
    "            output1 = q_model(normalizer(data))\n",
    "            output2 = fp_model(normalizer(data))\n",
    "            labels = [target.tolist()]\n",
    "            loss1 = ch.mean(diva_criterion(output1)[[i for i in range(0,output1.shape[0])],labels ][0])\n",
    "            loss2 = ch.mean(diva_criterion(output2)[[i for i in range(0,output2.shape[0])],labels ][0])\n",
    "\n",
    "    \n",
    "            loss = loss2 - c*loss1\n",
    "            \n",
    "            # Zero all existing gradients\n",
    "            q_model.zero_grad()\n",
    "            fp_model.zero_grad()\n",
    "            \n",
    "            # Calculate gradients of model in backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Collect datagrad\n",
    "            data_grad = data.grad.data\n",
    "            \n",
    "            # Call FGSM Attack\n",
    "            perturbed_data = fgsm_attack(data, orig_cpy, step, epsilon, data_grad)\n",
    "\n",
    "            # Re-classify the perturbed image\n",
    "            q_pred = q_model(normalizer(perturbed_data)).max(1, keepdim=True)[1].t()[0]\n",
    "            fp_pred = fp_model(normalizer(perturbed_data)).max(1, keepdim=True)[1].t()[0]\n",
    "\n",
    "            # Check for success\n",
    "            q_w = ch.logical_not(target == q_pred)\n",
    "            fp_c = (target == fp_pred)\n",
    "            \n",
    "            fp_c_q_w = ch.logical_and(q_w, fp_c)\n",
    "            index = ch.logical_not(fp_c_q_w)\n",
    "            \n",
    "            data = perturbed_data[index]\n",
    "            orig_cpy = orig_cpy[index]\n",
    "            \n",
    "            success += ch.sum(fp_c_q_w)\n",
    "            q_wrong += ch.sum(fp_c_q_w)\n",
    "            Q_success += ch.sum(fp_c_q_w)\n",
    "            fp_correct += ch.sum(fp_c_q_w)\n",
    "            \n",
    "            target = target[index]\n",
    "            \n",
    "            if iters == (grad_iterations -1) or len(target) == 0:\n",
    "                q_wrong += ch.sum(ch.logical_and(q_w, index))\n",
    "                Q_success += ch.sum(ch.logical_and(q_w, index))\n",
    "                fp_correct += ch.sum(ch.logical_and(fp_c, index))\n",
    "\n",
    "        ch.cuda.empty_cache()\n",
    "        # Calculate final accuracy for this epsilon\n",
    "        if i%100 == 0:\n",
    "            print(\"Total: {} \\t Success: {} \\t Q_W:{} \\t FP_W:{} \\t Adv_acc: {:.2f} \".format(Agree, success, q_wrong ,Agree - fp_correct, 100* (1- Q_success/((i+1) *BATCH_SIZE)) ))\n",
    "    print(\"Total: {} \\t Success: {} \\t Q_W:{} \\t FP_W:{} \\t Robust_acc: {:.2f} \".format(Agree, success, q_wrong ,Agree - fp_correct, 100* (1- Q_success/((i+1) *BATCH_SIZE)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIVA(q_model, fp_model, 1.5, device, val_loader, 0.00375, 0.03, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
