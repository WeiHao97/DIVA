{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "from matplotlib import pyplot\n",
    "from collections import Counter\n",
    "import json\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import enable_eager_execution\n",
    "enable_eager_execution()\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense, Input\n",
    "import keras_vggface #need installation\n",
    "from keras_vggface import utils\n",
    "from keras_vggface.vggface import VGGFace #need installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLossesKeras #need installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x_temp = np.copy(x)\n",
    "    x_temp = x_temp[..., ::-1]\n",
    "    x_temp[..., 0] -= 91.4953\n",
    "    x_temp[..., 1] -= 103.8827\n",
    "    x_temp[..., 2] -= 131.0912\n",
    "    return x_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Create Dataset and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,W= 224, 224 #Input Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadimgs(path,n = 0):\n",
    "    curr_y = n\n",
    "    person_dict={}\n",
    "    c=0\n",
    "    for person in os.listdir(path):\n",
    "        #print(\"loading person: \"+person)\n",
    "        person_path = os.path.join(path,person)\n",
    "        person_images=[]\n",
    "        for name in os.listdir(person_path):\n",
    "            image_path=os.path.join(person_path,name)\n",
    "            pixels = pyplot.imread(image_path)\n",
    "            image = tf.image.resize(pixels,[H,W]).numpy()\n",
    "            samples = preprocess_input(image)\n",
    "            person_images.append(samples)\n",
    "        person_dict[person]=person_images\n",
    "    return person_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../../../datasets/PubFig/CelebDataProcessed\"\n",
    "x=loadimgs(path)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label decoder: {label: person_name}\n",
    "label = 0\n",
    "label_dic = {}\n",
    "labels = []\n",
    "for k,v in x.items():\n",
    "    label_dic[k] = label\n",
    "    label += 1\n",
    "    labels.append(len(v))\n",
    "\n",
    "inv_map = {v: k for k, v in label_dic.items()}\n",
    "# with open(\"../../../datasets/PubFig/identities_decoder.json\", \"w\") as fp:\n",
    "#     json.dump(inv_map,fp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random shuffle\n",
    "for k,v in x.items():\n",
    "    x[k] = np.stack(random.sample(x[k],len(x[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test dataset, use 4 - 28 images per person, so we can guarentee there are at least 3 agreed images per person for the DIVA dataset  \n",
    "# we want the test dataset size be 1164 which is 10% of the whole dataset (11640)\n",
    "size = 0\n",
    "train_set = {}\n",
    "test_set = {}\n",
    "for k,v in x.items():\n",
    "    if len(v) == 403: # only one key has this many images\n",
    "        size += 28\n",
    "        test_set[k] = v[:28]\n",
    "        train_set[k] = v[28:]\n",
    "    elif len(v) >= 80:\n",
    "        size += 13\n",
    "        test_set[k] = v[:13]\n",
    "        train_set[k] = v[13:]\n",
    "    else:\n",
    "        size += 4\n",
    "        test_set[k] = v[:4]\n",
    "        train_set[k] = v[4:]\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create numpy array for train_x\n",
    "train_x = np.empty((0,H,W,3))\n",
    "train_y = []\n",
    "for k,v in train_set.items():\n",
    "    train_x = np.concatenate((train_x, v), axis=0)\n",
    "    train_y = train_y + np.full(shape=len(v), fill_value=label_dic[k], dtype=np.int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(train_x,train_y))\n",
    "\n",
    "random.shuffle(c) #Random permute\n",
    "\n",
    "train_x, train_y = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = np.array(train_x), np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../../../datasets/PubFig/train_x_10476.npy',train_x)\n",
    "# np.save('../../../datasets/PubFig/train_y_10476.npy',train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.empty((0,H,W,3))\n",
    "test_y = []\n",
    "for k,v in test_set.items():\n",
    "    test_x = np.concatenate((test_x, v), axis=0)\n",
    "    test_y = test_y + np.full(shape=len(v), fill_value=label_dic[k], dtype=np.int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(test_x,test_y))\n",
    "\n",
    "random.shuffle(c)\n",
    "\n",
    "test_x,test_y = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = np.array(test_x), np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../../../datasets/PubFig/test_x_1164.npy',test_x)\n",
    "# np.save('../../../datasets/PubFig/test_y_1164.npy',test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create VGGFACE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.Input(shape=(224, 224, 3))\n",
    "vgg_model = VGGFace(include_top=False, input_tensor=input,model='resnet50') # its called vgg but it uses resnet50\n",
    "x = Flatten(name='flatten')(vgg_model.output)\n",
    "out = Dense(150, activation='softmax', name='classifier')(x)\n",
    "model = tf.keras.Model(input, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train FP and Q models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5),\n",
    "#             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "#               metrics=['accuracy'])\n",
    "# model.fit(x=train_x,y=train_y,epochs =10,validation_data = (test_x,test_y),callbacks=[PlotLossesKeras()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model = tfmot.quantization.keras.quantize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5),\n",
    "#             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "#               metrics=['accuracy'])\n",
    "# q_model.fit(x=train_x,y=train_y,epochs =5,validation_data = (test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_model.save('../../../weights/q_model_90_pubface.h5')\n",
    "# model.save('../../../weights/fp_model_90_pubface.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Evaluate Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.load('../../../datasets/PubFig/test_x_1164.npy')\n",
    "test_y = np.load('../../../datasets/PubFig/test_y_1164.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model.load_weights('../../../weights/q_model_90_pubface.h5')\n",
    "model.load_weights('../../../weights/fp_model_90_pubface.h5')\n",
    "q_model.trainable =False\n",
    "model.trainable =False\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "q_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=2e-5),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model.evaluate(test_x,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Instability Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_correct = []\n",
    "q_correct = []\n",
    "for i in range(0,len(test_y)):\n",
    "    pred = np.argmax(model.predict(test_x[i][None,...])[0])\n",
    "    q_pred = np.argmax(q_model.predict(test_x[i][None,...])[0])\n",
    "    label = test_y[i]\n",
    "    if pred == label:\n",
    "        fp_correct.append(i)\n",
    "    if q_pred == label:\n",
    "        q_correct.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_correct = len(q_correct )\n",
    "orig_correct = len(fp_correct)\n",
    "q_correct_orig_wrong = len(set(q_correct).difference(set(fp_correct)))\n",
    "q_wrong_orig_correct = len(set(fp_correct).difference(set(q_correct)))\n",
    "print(quant_correct, orig_correct, q_correct_orig_wrong, q_wrong_orig_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert model to tflite format that can run on aarch64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "# with open(\"../../../weights/tflite_int8_model_90.tflite\", 'wb') as f:\n",
    "#     f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset for DIVA test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []# index for the agreed images for DIVA evaluation\n",
    "fp_y = []\n",
    "q_y = []\n",
    "for i in range(0,len(test_y)):\n",
    "    pred = np.argmax(model.predict(test_x[i][None,...])[0])\n",
    "    q_pred = np.argmax(q_model.predict(test_x[i][None,...])[0])\n",
    "    label = test_y[i]\n",
    "    fp_y.append(pred)\n",
    "    q_y.append(q_pred)\n",
    "    if pred == q_pred and pred == label:\n",
    "        index.append(i)\n",
    "condidate_x = test_x[np.array(index)]\n",
    "condidate_y = test_y[np.array(index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./results/test_fp_1164.npy',np.array(fp_y))\n",
    "# np.save('./results/test_q_1164.npy',np.array(q_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(int)\n",
    "dataset_y = []\n",
    "dataset_x =np.empty((0,224,224,3))\n",
    "for i in range(0,len(condidate_y)):\n",
    "    if d[condidate_y[i]] < 3:# 3 images per person\n",
    "        dataset_x = np.concatenate((dataset_x, condidate_x[i][None,...]), axis=0)\n",
    "        dataset_y.append(condidate_y[i])\n",
    "        d[condidate_y[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../../../datasets/PubFig/dataset_y_450.npy',np.array(dataset_y))\n",
    "# np.save('../../../datasets/PubFig/dataset_x_450.npy',dataset_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Record Success Rate and Confidence Score for Analysis( results from wb_fr.py or pgd_fr.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail = {1: 'failure/', 0: ''}\n",
    "wb = {1: 'wb', 0: 'pgd'}\n",
    "WB = {1: 'WB', 0: 'PGD'}\n",
    "flag = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = wb[flag]\n",
    "fail = fail[flag]\n",
    "WB = WB[flag]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Top-1 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = {}\n",
    "for filename in sorted(os.listdir('./results/'+ WB + '/' + fail +'images_second/')):\n",
    "    if filename.endswith('.npy'):\n",
    "        if '@' in filename:\n",
    "            arrays[filename] = (np.load('./results/'+ WB + '/' + fail +'images_second/' + filename),np.load('./results/'+ WB + '/' + fail +'filters_second/' + filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageplusfilter = list(arrays.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = list(arrays.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_images_deprocess = np.array([(x[0] - x[1]) for x in imageplusfilter ])\n",
    "ad_images_deprocess = np.array([x[0] for x in imageplusfilter ])\n",
    "orig_images = np.array([preprocess_input(x[0] - x[1]) for x in imageplusfilter ])\n",
    "ad_images = np.array([preprocess_input(x[0]) for x in imageplusfilter ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_label = []\n",
    "orig_score = []\n",
    "ad_score = []\n",
    "for i in range(0,len(orig_images)):\n",
    "    orig_img = backend.constant(orig_images[i])[None,...]\n",
    "    ad_img = backend.constant(ad_images[i])[None,...]\n",
    "    fp_label.append(np.argmax(model.predict(orig_img)[0])) # predicted labelfrom the fp_model\n",
    "    orig_score.append(model.predict(orig_img)[0][fp_label[i]]) # prediction score from the fp_model\n",
    "    ad_score.append(model.predict(ad_img)[0][fp_label[i]]) # prediction score from the fp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail = {1: '_failure', 0: ''}\n",
    "fail = fail[flag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record these and compare them with the ones from the tflite model (script in FaceRocognization_Aarch64.ipynb)\n",
    "# np.save('./results/' + WB + '/' + wb +'_y' + fail + '_v2.npy', np.array(fp_label))\n",
    "# np.save('./results/' + WB + '/' + wb +'_x' + fail + '_orig_v2.npy', np.array(orig_images_deprocess))\n",
    "# np.save('./results/' + WB + '/' + wb +'_x' + fail + '_ad_v2.npy', np.array(ad_images_deprocess))\n",
    "# np.save('./results/' + WB + '/' + wb +'_fp_v2' + fail + '_orig_score.npy', np.array(orig_score))\n",
    "# np.save('./results/' + WB + '/' + wb +'_fp_v2' + fail + '_ad_score.npy', np.array(ad_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Top-5 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = {}\n",
    "for filename in sorted(os.listdir('./results/'+ WB + '/images_second/')):\n",
    "    if filename.endswith('.npy'):\n",
    "        if not '@' in filename:\n",
    "            arrays[filename] = np.load('./results/'+ WB + '/images_second/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = np.array(list(arrays.values()))\n",
    "success_ = np.array([preprocess_input(x) for x in success])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_label = []\n",
    "fp_label = []\n",
    "for image in success_:\n",
    "    img = backend.constant(image)[None,...]\n",
    "    pgd_fp_label.append(model.predict(img)[0].argsort()[-5:][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record these and compare them with the ones from the tflite model (script in FaceRocognization_Aarch64.ipynb)\n",
    "# np.save('./results/' + WB + '/' + wb +'_5_y_v2.npy', np.array(fp_label))\n",
    "# np.save('./results/' + WB + '/' + wb +'_5_x_v2.npy', np.array(success))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
