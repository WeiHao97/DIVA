{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import png\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert path files appropriately for data which can be found after generation in results folder for this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = \"res\"\n",
    "attack = \"PGD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = \"1\" # Hyperparameter C value from data\n",
    "locald = '../ImageNet/results/'+ attack +'/DIVA/'+net+'net/' # Please change to the corresponding results folder for evaluation\n",
    "folderName= net + 'net_imagenet_images_second'\n",
    "filterName= net +'net_imagenet_filters_second'\n",
    "dataFolder= net +'net_imagenet_data_second'\n",
    "dataName= 'second'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats():\n",
    "    advist_data = np.array([])\n",
    "\n",
    "    with open(locald + dataFolder+\"/\"+dataName+'_advdist_data.csv', 'r') as filehandle:\n",
    "        for line in filehandle:\n",
    "            temp_data = line[:-2]\n",
    "\n",
    "        advist_data = np.concatenate((advist_data, np.array(temp_data.split(\", \"))))\n",
    "        \n",
    "    steps_data = np.array([])\n",
    "\n",
    "    with open(locald +dataFolder+\"/\"+dataName+'_steps_data.csv', 'r') as filehandle:\n",
    "        for line in filehandle:\n",
    "            temp_data = line[:-2]\n",
    "\n",
    "        steps_data = np.concatenate((steps_data, np.array(temp_data.split(\", \"))))\n",
    "    \n",
    "    time_data = np.array([])\n",
    "\n",
    "    with open(locald +dataFolder+\"/\"+dataName+'_time_data.csv', 'r') as filehandle:\n",
    "        for line in filehandle:\n",
    "            temp_data = line[:-2]\n",
    "\n",
    "        time_data = np.concatenate((time_data, np.array(temp_data.split(\", \"))))\n",
    "    \n",
    "    advist_datak = np.array([])\n",
    "\n",
    "    with open(locald +dataFolder+\"/\"+dataName+'_advdistk_data.csv', 'r') as filehandle:\n",
    "        for line in filehandle:\n",
    "            temp_data = line[:-2]\n",
    "\n",
    "        advist_datak = np.concatenate((advist_datak, np.array(temp_data.split(\", \"))))\n",
    "        \n",
    "    steps_datak = np.array([])\n",
    "\n",
    "    with open(locald +dataFolder+\"/\"+dataName+'_stepsk_data.csv', 'r') as filehandle:\n",
    "        for line in filehandle:\n",
    "            temp_data = line[:-2]\n",
    "\n",
    "        steps_datak = np.concatenate((steps_datak, np.array(temp_data.split(\", \"))))\n",
    "    \n",
    "    time_datak = np.array([])\n",
    "\n",
    "    with open(locald +dataFolder+\"/\"+dataName+'_timek_data.csv', 'r') as filehandle:\n",
    "        for line in filehandle:\n",
    "            temp_data = line[:-2]\n",
    "\n",
    "        time_datak = np.concatenate((time_datak, np.array(temp_data.split(\", \"))))\n",
    "    \n",
    "    time_data = time_data.astype('float')\n",
    "    advist_data = advist_data.astype('float')\n",
    "    steps_data = steps_data.astype('float')\n",
    "\n",
    "    time_datak = time_datak.astype('float')\n",
    "    advist_datak = advist_datak.astype('float')\n",
    "    steps_datak = steps_datak.astype('float')\n",
    "\n",
    "    time_data_ = np.mean(time_data), np.std(time_data)\n",
    "    advdist_data_ = np.mean(advist_data), np.std(advist_data)\n",
    "    steps_data_ = np.mean(steps_data), np.std(steps_data)\n",
    "\n",
    "    time_datak_ = np.mean(time_datak), np.std(time_datak)\n",
    "    advdist_datak_ = np.mean(advist_datak), np.std(advist_datak)\n",
    "    steps_datak_ = np.mean(steps_datak), np.std(steps_datak)\n",
    "    \n",
    "    print(\"Number of Successes\",len(steps_data))\n",
    "    print(\"Total Time\",np.sum(time_data)) \n",
    "    print(\"Total Steps\",np.sum(steps_data))\n",
    "    print(\"Steps\",steps_data_)\n",
    "    print(\"Time\", time_data_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Time5\",time_datak_) \n",
    "    print(\"Dist5\",advdist_datak_) \n",
    "    print(\"Steps5\",steps_datak_)\n",
    "    \n",
    "    print()\n",
    "    print(\"Number of top1 success\",(len(steps_data))/3000)\n",
    "    print(\"Number of top5 success\",len(steps_datak)/3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c 1\n",
      "Number of Successes 1526\n",
      "Total Time 3650.976760864258\n",
      "Total Steps 2152.0\n",
      "Steps (1.4102228047182175, 2.395277207181673)\n",
      "Time (2.392514260068321, 2.374536337122452)\n",
      "\n",
      "Time5 (8.734358531400344, 4.452879560951598)\n",
      "Dist5 (6.568666906623586, 2.0501910348206627)\n",
      "Steps5 (7.796445880452342, 4.511044099835148)\n",
      "\n",
      "Number of top1 success 0.5086666666666667\n",
      "Number of top5 success 0.20633333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"c\", c)\n",
    "print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Custom layers for DenseNet to support quantisation\n",
    "'''\n",
    "\n",
    "class DefaultBNQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
    "\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "        return []\n",
    "\n",
    "    def get_activations_and_quantizers(self, layer):\n",
    "        return []\n",
    "\n",
    "    def set_quantize_weights(self, layer, quantize_weights):\n",
    "        pass\n",
    "    def set_quantize_activations(self, layer, quantize_activations):\n",
    "        pass\n",
    "    def get_output_quantizers(self, layer):\n",
    "        return [tfmot.quantization.keras.quantizers.MovingAverageQuantizer(num_bits=8, per_axis=False, symmetric=False, narrow_range=False)]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}\n",
    "    \n",
    "    \n",
    "class NoOpQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
    "    \"\"\"Use this config object if the layer has nothing to be quantized for \n",
    "    quantization aware training.\"\"\"\n",
    "\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "        return []\n",
    "\n",
    "    def get_activations_and_quantizers(self, layer):\n",
    "        return []\n",
    "\n",
    "    def set_quantize_weights(self, layer, quantize_weights):\n",
    "        pass\n",
    "\n",
    "    def set_quantize_activations(self, layer, quantize_activations):\n",
    "        pass\n",
    "\n",
    "    def get_output_quantizers(self, layer):\n",
    "        # Does not quantize output, since we return an empty list.\n",
    "        return []\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}\n",
    "    \n",
    "    \n",
    "def apply_quantization(layer):\n",
    "    if 'bn'  in layer.name:\n",
    "        return tfmot.quantization.keras.quantize_annotate_layer(layer,DefaultBNQuantizeConfig())\n",
    "    elif 'concat' in layer.name:\n",
    "        return tfmot.quantization.keras.quantize_annotate_layer(layer,NoOpQuantizeConfig())\n",
    "    else:\n",
    "        return tfmot.quantization.keras.quantize_annotate_layer(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 224 ,224\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet Done\n"
     ]
    }
   ],
   "source": [
    "if net == \"res\":\n",
    "    model_ = ResNet50(input_shape=input_shape)\n",
    "    q_model = tfmot.quantization.keras.quantize_model(model_)\n",
    "    model = ResNet50(input_tensor = q_model.input)\n",
    "    model.load_weights(\"../../weights/fp_model_40_resnet50.h5\")\n",
    "    q_model.load_weights(\"../../weights/q_model_40_resnet50.h5\")\n",
    "    print(\"ResNet Done\")\n",
    "    \n",
    "elif net == \"mobile\":\n",
    "    model_ = MobileNet(input_shape=input_shape)\n",
    "    q_model = tfmot.quantization.keras.quantize_model(model_)\n",
    "    model = MobileNet(input_tensor = q_model.input)\n",
    "    model.load_weights(\"../../weights/fp_model_40_mobilenet.h5\")\n",
    "    q_model.load_weights(\"../../weights/q_model_40_mobilenet.h5\")\n",
    "    print(\"MobNet Done\")\n",
    "    \n",
    "else:\n",
    "    model_ = tf.keras.applications.DenseNet121(input_shape=(img_rows, img_cols,3))\n",
    "    # Create a base model\n",
    "    base_model = model_\n",
    "    # Helper function uses `quantize_annotate_layer` to annotate that only the \n",
    "    # Dense layers should be quantized.\n",
    "\n",
    "    LastValueQuantizer = tfmot.quantization.keras.quantizers.LastValueQuantizer\n",
    "    MovingAverageQuantizer = tfmot.quantization.keras.quantizers.MovingAverageQuantizer\n",
    "\n",
    "    # Use `tf.keras.models.clone_model` to apply `apply_quantization_to_dense` \n",
    "    # to the layers of the model.\n",
    "    annotated_model = tf.keras.models.clone_model(\n",
    "        base_model,\n",
    "        clone_function=apply_quantization,\n",
    "    )\n",
    "\n",
    "    with tfmot.quantization.keras.quantize_scope({'DefaultBNQuantizeConfig': DefaultBNQuantizeConfig, 'NoOpQuantizeConfig': NoOpQuantizeConfig}):\n",
    "        q_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
    "\n",
    "    model = DenseNet121(input_tensor = q_model.input)\n",
    "    model.load_weights(\"../../weights/fp_model_40_densenet121.h5\")\n",
    "    q_model.load_weights(\"../../weights/q_model_40_densenet121.h5\")\n",
    "    print(\"DenseNet Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable = False\n",
    "q_model.trainable = False\n",
    "model.compile() \n",
    "q_model.compile() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appropriate Preprocessing and Decoding predictions\n",
    "if net==\"res\":\n",
    "    preproc = tf.keras.applications.resnet.preprocess_input\n",
    "elif net==\"mobile\":\n",
    "    preproc = tf.keras.applications.mobilenet.preprocess_input\n",
    "else:\n",
    "    preproc = tf.keras.applications.densenet.preprocess_input\n",
    "\n",
    "    #Choose model\n",
    "if net==\"res\":\n",
    "    dec = tf.keras.applications.resnet.decode_predictions\n",
    "elif net==\"mobile\":\n",
    "    dec = tf.keras.applications.mobilenet.decode_predictions\n",
    "else:\n",
    "    dec = tf.keras.applications.densenet.decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Generated Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = {'file_name': tf.TensorSpec(shape=(), dtype=tf.string, name=None),\n",
    " 'image': tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None),\n",
    " 'label': tf.TensorSpec(shape=(), dtype=tf.int64, name=None)}\n",
    "\n",
    "mydataset = tf.data.experimental.load(\"../../datasets/Imagenet/quantisation/3kImages/\",es).batch(20).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSSIM Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this job you must have dssim downloaded which can be done byusing their github link, https://github.com/kornelski/dssim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job1(image,fil,og):\n",
    "    \n",
    "    tf.keras.preprocessing.image.save_img(\"fake1.png\", image)\n",
    "    tf.keras.preprocessing.image.save_img(\"real1.png\", og)\n",
    "    \n",
    "    process = subprocess.run(['./path/to/dssim','fake1.png','real1.png'], \n",
    "                         stdout=subprocess.PIPE,\n",
    "                         stderr=subprocess.PIPE,\n",
    "                         universal_newlines=True)\n",
    "    if process.stdout.split('\\t')[0] == '':\n",
    "        print(process.stderr)\n",
    "    else:\n",
    "        dssim_data.append(process.stdout.split('\\t')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Delta Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job2(image, fil, og):\n",
    "    \n",
    "    image = np.copy(image)\n",
    "    og = np.copy(og)\n",
    "    \n",
    "    real = np.expand_dims(og, axis=0)\n",
    "    attack = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    pred1, pred2= model.predict(real), q_model.predict(real)\n",
    "    \n",
    "    real_r_pred = dec(pred1, top=1000)\n",
    "    real_q_pred = dec(pred2, top=1000)\n",
    "    \n",
    "    pred1, pred2= model.predict(attack), q_model.predict(attack)\n",
    "    \n",
    "    attack_r_pred = dec(pred1, top=1000)\n",
    "    attack_q_pred = dec(pred2, top=1000)\n",
    "    \n",
    "    r_label = real_r_pred[0][0][1]\n",
    "    \n",
    "    print(r_label)\n",
    "    \n",
    "    rr = float(real_r_pred[0][0][2]) #Correct Label \n",
    "    rq = float(real_q_pred[0][0][2]) #Correct Label \n",
    "    \n",
    "    for i in range(0,1000):\n",
    "        if attack_q_pred[0][i][1] == r_label:\n",
    "            aq = float(attack_q_pred[0][i][2])\n",
    "            break\n",
    "                       \n",
    "    for i in range(0,1000):\n",
    "        if attack_r_pred[0][i][1] == r_label:\n",
    "            ar = float(attack_r_pred[0][i][2])\n",
    "            break\n",
    "    \n",
    "    \n",
    "    confRR_data.append(rr)\n",
    "    confAR_data.append(ar)\n",
    "    confRQ_data.append(rq)\n",
    "    confAQ_data.append(aq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job3(image,fil,og):\n",
    "    \n",
    "    image = np.copy(image)\n",
    "    og = np.copy(og)\n",
    "      \n",
    "    real = np.expand_dims(preproc(og), axis=0)\n",
    "    attack = np.expand_dims(preproc(image), axis=0)\n",
    "    \n",
    "    pred1, pred2= model.predict(real), q_model.predict(real)\n",
    "    \n",
    "    r_label = np.argmax(pred1)\n",
    "    \n",
    "    pred1, pred2= model.predict(attack), q_model.predict(attack)\n",
    "    \n",
    "    attack_r_pred = np.argmax(pred1)\n",
    "    attack_q_pred = np.argmax(pred2)\n",
    "    \n",
    "    if (r_label == attack_r_pred and r_label == attack_q_pred):\n",
    "        CC[0] += 1\n",
    "        return\n",
    "    if (r_label != attack_r_pred and r_label != attack_q_pred):\n",
    "        WW[0] += 1\n",
    "        return\n",
    "    if (r_label != attack_r_pred and r_label == attack_q_pred):\n",
    "        WC[0] += 1\n",
    "        return\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data variables for evaluation. Please fill in the appropriate data folder names for the different models in order to evaluate\n",
    "'''\n",
    "\n",
    "folderName= net + 'net_imagenet_images_second'\n",
    "filterName= net +'net_imagenet_filters_second'\n",
    "dataFolder= net +'net_imagenet_data_second'\n",
    "\n",
    "failureFolderName='failure/' + folderName\n",
    "failureFilterName='failure/' + filterName\n",
    "\n",
    "dataName= 'second'\n",
    "\n",
    "#Job1\n",
    "dssim_data = []\n",
    "\n",
    "#Job5\n",
    "confRR_data = []\n",
    "confAR_data = []\n",
    "confRQ_data = []\n",
    "confAQ_data = []\n",
    "\n",
    "#Job4\n",
    "CW = [0]\n",
    "CC = [0]\n",
    "WC = [0]\n",
    "WW = [0]\n",
    "\n",
    "count = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Processing Failures\n",
      "273\n",
      "scoreboard\n",
      "171\n",
      "chain_mail\n",
      "1245\n",
      "spotlight\n",
      "89\n",
      "corn\n",
      "835\n",
      "maze\n",
      "775\n",
      "radio\n",
      "1457\n",
      "lampshade\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c7c7a8002730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mjob2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfil\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mjob3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfil\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-72f3afdabf96>\u001b[0m in \u001b[0;36mjob3\u001b[0;34m(image, fil, og)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mr_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpred1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mattack_r_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                         '. Consider setting it to AutoShardPolicy.DATA.')\n\u001b[1;32m   1597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1599\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     \"\"\"\n\u001b[1;32m   1804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4206\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4207\u001b[0m         use_legacy_function=use_legacy_function)\n\u001b[0;32m-> 4208\u001b[0;31m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[0m\u001b[1;32m   4209\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmap_dataset\u001b[0;34m(input_dataset, other_arguments, f, output_types, output_shapes, use_inter_op_parallelism, preserve_cardinality, name)\u001b[0m\n\u001b[1;32m   3019\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3022\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MapDataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_arguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m         \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Files for images and filters are found and the original image is rebuilt, which is then used for further analysis\n",
    "'''\n",
    "\n",
    "for i,filename in enumerate(os.listdir(locald + folderName)):\n",
    "    continue\n",
    "\n",
    "    try:\n",
    "        filename.index(\"@\")\n",
    "    except:\n",
    "        print(filename)\n",
    "        continue\n",
    "        \n",
    "    if filename.endswith('.npy'):\n",
    "        count[0]+=1\n",
    "        CW[0] += 1\n",
    "        \n",
    "        numbers = filename[6:].split('@')\n",
    "        position = int(numbers[0])\n",
    "        total = int(numbers[1][:-4])\n",
    "        \n",
    "        print(position)\n",
    "        \n",
    "        image = np.load(locald +folderName+\"/\"+filename)\n",
    "        fil = np.load(locald +filterName+\"/\"+filename)\n",
    "        og = image - fil\n",
    "        \n",
    "#         job1(image,fil, og)\n",
    "        job2(image,fil,og)\n",
    "        \n",
    "print(count[0])\n",
    "print(\"Processing Failures\")\n",
    "\n",
    "for i,filename in enumerate(os.listdir(locald + failureFolderName)):\n",
    "    \n",
    "    try:\n",
    "        filename.index(\"@\")\n",
    "    except:\n",
    "        print(filename)\n",
    "        continue\n",
    "        \n",
    "    if filename.endswith('.npy'):\n",
    "        count[0]+=1\n",
    "        numbers = filename[6:].split('@')\n",
    "        position = int(numbers[0])\n",
    "        total = int(numbers[1][:-4])\n",
    "        \n",
    "        print(position)\n",
    "        \n",
    "        image = np.load(locald +failureFolderName+\"/\"+filename)\n",
    "        fil = np.load(locald +failureFilterName+\"/\"+filename)\n",
    "        og = image - fil\n",
    "        \n",
    "        job2(image,fil,og)\n",
    "        job3(image,fil,og)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysed and Saved Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert name of data file stored here to be graphed and visualised later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open(\"../Imagenet/Results/INSERT_NAME.csv\", \"w\")\n",
    "\n",
    "for element in confRR_data:\n",
    "    textfile.write(str(element) + \", \")\n",
    "\n",
    "textfile.write(\"\\n\")\n",
    "\n",
    "for element in confRQ_data:\n",
    "    textfile.write(str(element) + \", \")\n",
    "\n",
    "textfile.write(\"\\n\")\n",
    "\n",
    "for element in confAR_data:\n",
    "    textfile.write(str(element) + \", \")\n",
    "\n",
    "textfile.write(\"\\n\")\n",
    "\n",
    "for element in confAQ_data:\n",
    "    textfile.write(str(element) + \", \")\n",
    "\n",
    "textfile.write(\"\\n\")\n",
    "\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[14]\n",
      "[0]\n",
      "[6]\n",
      "20\n",
      "0.007\n"
     ]
    }
   ],
   "source": [
    "print(CC)\n",
    "print(CW)\n",
    "print(WC)\n",
    "print(WW)\n",
    "print(CC[0]+WC[0]+CW[0]+WW[0])\n",
    "print(count[0]/3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dssim_data = np.array(dssim_data).astype(float)\n",
    "np.mean(dssim_data),np.std(dssim_data),np.max(dssim_data),len(dssim_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
